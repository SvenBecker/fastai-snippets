{
    "Train Template": {
        "prefix": "fastai:train_2s",
        "description": "Two stage training template",
        "body": [
            "learn.${1|fit,fit_one_cycle|}(${2:5}, ${3:5e-3})",
            "learn.save('stage-1')",
            "",
            "learn.lr_find()",
            "learn.recorder.plot()",
            "",
            "learn.unfreeze()",
            "learn.${4|fit,fit_one_cycle|}(${5:5}, ${6:slice(1e-3 / 2.6**4 ,1e-3}))",
            "learn.save('stage-2')"
        ]
    },
    "Train": {
        "prefix": "fastai:train",
        "description": "Fit function",
        "body": [
            "learn.${1|fit,fit_one_cycle|}(${2:5}, ${3:1e-3})"
        ]
    },
    "Metric Template": {
        "prefix": "fastai:metric",
        "desription": "Creates a metric function template",
        "body": [
            "def ${1:metric}(pred: Tensor, targ: Tensor):",
            "\t# Computes the ${1:metric} between `pred` an `targ`",
            "\treturn"
        ]
    },
    "Regression Metrics": {
        "prefix": "fastai:metric_reg",
        "desription": "Adds a regression metrics",
        "body": [
            "metrics = [${1|exp_rmspe|}]"
        ]
    },
    "Classification Metrics": {
        "prefix": "fastai:metric_class",
        "desription": "Adds a classification metrics",
        "body": [
            "metrics = [${1|accuracy,accuracy_thresh,dice,error_rate,fbeta|}]"
        ]
    },
    "Classification Loss": {
        "prefix": "fastai:loss_class",
        "desription": "Select a classification loss functione",
        "body": [
            "${1:learn}.loss = ${2|CrossEntropyFlat,nn.BCELoss,nn.BCEWithLogitsLoss,nn.CrossEntropyLoss,nn.MarginRankingLoss,nn.NLLLoss,nn.PoissonNLLLoss,nn.HingeEmbeddingLoss,nn.MultiLabelMarginLoss,nn.SoftMarginLoss,nn.MultiLabelSoftMarginLoss,nn.CosineEmbeddingLoss,nn.MultiMarginLoss,nn.TripletMarginLoss|}()"
        ]
    },
    "Regression Loss": {
        "prefix": "fastai:loss_reg",
        "desription": "Select a regression loss function",
        "body": [
            "${1:learn}.loss = ${2|MSELossFlat,nn.L1Loss,nn.MSELoss,nn.KLDivLoss,nn.SmoothL1Loss|}()"
        ]
    },
    "Optimizer": {
        "prefix": "fastai:optimizer",
        "desription": "Select an optimizer",
        "body":[
            "optimizer = optim.${1|Adadelta,Adagrad,Adam,SparseAdam,Adamax,ASGD,LBFGS,RMSprop,Rprop,SGD|}"
        ]
    },
    "Download Dataset": {
        "prefix": "fastai:download-dataset",
        "desription": "Select a data set to download or to import, if it is already available",
        "body":[
            "path = untar_data(URLS.${1|LOCAL_PATH,S3,S3_IMAGE,S3_IMAGELOC,S3_NLP,S3_COCO,S3_MODEL,COCO_SAMPLE,COCO_TINY,MNIST_SAMPLE,MNIST_TINY,IMDB,IMDB_SAMPLE,HUMAN_NUMBERS,ADULT_SAMPLE,ML_SAMPLE,PLANET_SAMPLE,PLANET_TINY,CIFAR,WT103,DOGS,PETS,MNIST,CAMVID,CAMVID_TINY|}, fname=${2:None}, dest=${3:None}, data=${4|True,False|})"
        ]
    },
    "Vision Imports": {
        "prefix": "fastai:vision:imports",
        "description": "Imports the packages which are most required for computer vision tasks",
        "body": [
            "from fastai import *",
            "from fastai.vision import *"
        ]
    },
    "Image Transform": {
        "prefix": "fastai:vision:transform",
        "description": "Image transformation pipeline",
        "body": [
            "tfms = get_transforms(do_flip=${1|True,False|}, flip_vert=${2|False,True|}, max_rotate=${3:10.}, max_zoom=${4:1.1},",
            "\tmax_lightning=${5:0.2}, max_warp=${6:0.2}, p_affine=${7:0.75}, p_lightning=${8:0.75})"
        ]
    },
    "Image Normalize Stats": {
        "prefix": "fastai:vision:stats",
        "description": "Select normalization stats",
        "body": [
            "${1|imagenet_stats,cifar_stats,mnist_stats,()|}"
        ]
    },
    "Image DataBlock": {
        "prefix": "fastai:vision:datablock",
        "description": "Creates a DataBlock for image data",
        "body": [
            "tfms = get_transforms(do_flip=${1|True,False|}, flip_vert=${2|False,True|}, max_rotate=${3:10.}, max_zoom=${4:1.1},",
            "\tmax_lightning=${5:0.2}, max_warp=${6:0.2}, p_affine=${7:0.75}, p_lightning=${8:0.75})",
            "path = Path('${TM_DIRECTORY}') / '${9:data'}",
            "size = ${10:128}",
            "src = (${11|ImageItemList.from_folder(path),ImageSplitDatasets(path)|}\t# grab all files from path",
            "\t.${12|label_const(const=0)\t# label every item with const,label_from_csv(csv_fnames\\, fn_col=0\\, label_col=1\\, header='infer')\t# look in self.path/csv_fname for a csv loaded with an optional header containing the filenames in fn_col to get the corresponding label in label_col,label_from_folder(classes=None)\t# give a label to each filename depending on its folder,label_from_df(df\\, fn_col=0\\, label_col=1)\t# look in df for the filenames in fn_col to get the corresponding label in label_col,label_from_func(get_y_fn)\t# apply func to every input to get its label,label_from_re(pat\\, full_path=False)\t# apply the re in pat to determine the label of every filename|}",
            "\t.${13|split_by_folder(train='train'\\, valid='valid')\t# split the data depending on the folder in which the filenames are,random_split_by_pct(valid_pct=0.2)\t# split the items randomly by putting valid_pct in the validation set,split_by_files(valid_names)\t# split the data by using the names in valid_names for validation,split_by_fname_file(fname)\t# split the data by using the file names in fname for the validation set,split_by_idx(valid_idx)\t# split the data according to the indexes in valid_idx,split_by_valid_func(func)\t# split the data by result of func (which returns True for validation set)|}",
            "\t${14|),.add_test(test\\, label=None))\t# add test set containing items from test and an arbitrary label|}",
            "data = (src.datasets(${15|ImageClassificationDataset,ImageMultiDataset,SegmentationDataset,PointsDataset,ObjectDataset|})\t# create datasets from the underlying data using dataset_cls and passing along the kwargs",
            "\t.transform(tfms, size=size, tfm_y=${16|False,True|})",
            "\t.databunch(bs=${17:32})",
            "\t.normalize(${18|imagenet_stats,cifar_stats,mnist_stats,()|}))",
            "data.save('tmp_data')"
        ]
    },
    "Image DataBunch": {
        "prefix": "fastai:vision:databunch",
        "description": "Creates a DataBunch for image data",
        "body": [
            "img_path = Path('${TM_DIRECTORY}') / ${1:'images'}",
            "bs=${2:64}",
            "size=${3:224}",
            "tfms=get_transforms(do_flip=${4|True,False|}, flip_vert=${5|False,True|}, max_rotate=${6:10.}, max_zoom=${7:1.1},", 
            "\tmax_lightning=${8:0.2}, max_warp=${9:0.2}, p_affine=${10:0.75}, p_lightning=${11:0.75})",
            "",
            "data = ImageDataBunch.${12|create(path=img_path\\, train_ds=train_ds\\, valid_ds=valid_ds\\, test_ds=None\\, size=size\\, bs=bs\\, tfms=tfms),from_folder(path_img\\, train='train'\\, valid='valid'\\, test=None\\, size=size\\, bs=bs\\, tfms=tfms),from_df(path=img_path\\, df=df\\, folder='.'\\, sep=None\\, valid_pct=0.2\\, fn_col=0\\, label_col=1\\, test=None\\, suffix=None\\, size=size\\, bs=bs\\,  tfms=tfms),from_csv(path:img_path\\, folder='.'\\, sep=None\\, csv_labels='labels.csv'\\, valid_pct=0.2\\, fn_col=0\\, label_col=1\\, test=None\\, suffix=None\\, header='infer'\\, size=size\\, bs=bs\\, tfms=tfms),from_lists(path=img_path\\, fnames=fnmaes\\, labels=labels\\, valid_pct=0.2\\, test=None\\, size=size\\, bs=bs\\, tfms=tfms),from_name_func(path=img_path\\, fnames=fnames\\, label_func=label_func\\, valid_pct=0.2\\, test=None\\, size=size\\, bs=bs\\, tfms=tfms),from_name_re(path=path_img\\, fnames=fnames\\, pat=pattern\\, valid_pct=0.2\\, test=None\\, size=size\\, bs=bs\\, tfms=tfms)|}",
            "data.normalize(stats=${13|None,imagenet_stats,cifar_stats,mnist_stats,()|})"
        ]
    },
    "Image Classifier": {
        "prefix": "fastai:vision:classifier",
        "description": "Creates an ImageClassifier",
        "body": [
            "arch = ${1|None,models.resnet18,models.resnet34,models.resnet50,models.resnet101,models.resnet152,models.wrn_22|}",
            "custom_head = ${2|None,create_head(num_features\\, num_classes\\, lin_ftrs=None\\, ps=0.5)|}",
            "metrics = ${3|error_rate,accuracy,accuracy_thresh,dice|}",
            "learn = create_cnn(data, arch=arch, metrics=metrics,cut=None, pretrained=True, lin_ftrs=None, ps=0.5, custom_head=custom_head, split_on=None)"
        ]
    },
    "ImageClassifier Interpretation": {
        "prefix": "fastai:vision:interpreter",
        "description": "Creates an ImageClassifierInterpreter",
        "body": [
            "interp = ClassificationInterpretation${1|.from_learner(learn\\, tta=False),(data\\, probs\\, y_true\\, losses)|}",
            "interp.${2|top_losses(k=None\\, largest=True),plot_top_losses(k\\, largest=True\\, figsize=(12\\,12)),confusion_matrix(),plot_confusion_matrix(normalize=False\\, title'Confusion matrix'\\, cmap='Blues'\\, norm_dec=2),most_confused(min_val=1)|}"
        ]
    },
    "Tabular Imports": {
        "prefix": "fastai:tabular:imports",
        "description": "Adds most important imports for tabular data tasks",
        "body": [
            "from fastai import *",
            "from fastai.tabular import *"
        ]
    },
    "Tabular DataBlock": {
        "prefix": "fastai:tabular:datablock",
        "description": "Creates a DataBlock for tabular/structured data",
        "body": [
            "path = Path('${TM_DIRECTORY}') / '${1:data'}",
            "cat_names = [$2]",
            "cont_names = [$3]",
            "procs = [FillMissing, Categorify, Normalize]",
            "",
            "data = (TabularList.from_df(${4:df}, path=path, cat_names=cat_names, cont_names=cont_names, procs=procs)",
            "\t.${5|split_by_folder(train='train'\\, valid='valid')\t# split the data depending on the folder in which the filenames are,random_split_by_pct(valid_pct=0.2)\t# split the items randomly by putting valid_pct in the validation set,split_by_files(valid_names)\t# split the data by using the names in valid_names for validation,split_by_fname_file(fname)\t# split the data by using the file names in fname for the validation set,split_by_idx(valid_idx)\t# split the data according to the indexes in valid_idx,split_by_valid_func(func)\t# split the data by result of func (which returns True for validation set)|}",
            "\t.label_from(cols=dep_var)",
            "\t${6| ,.add_test(test\\, label=0))\t# add test set containing items from test and an arbitrary label|}",
            "\t.databunch(bs=${7:32})",
            "data.save('tmp_data')"
        ]
    },
    "Tabular DataBunch": {
        "prefix": "fastai:tabular:databunch",
        "description": "Creates a DataBuch for tabular data",
        "body": [
            "path = Path('${TM_DIRECTORY}') / '${1:data}'",
            "data = TabularDataBunch.from_df(path, ${2:train_df}, ${3:valid_df}, ${4:dep_var}, test_df=None, tfms=None, cat_names=None, cont_names=None, stats=None, log_output=False)"
        ]
    },
    "Tabular Learner": {
        "prefix": "fastai:tabular:learner",
        "description": "Creates a learner for tabular data",
        "body": [
            "learn = tabular_learner(${1:data}, layers=${2:2}, metrics=${3|error_rate,accuracy,accuracy_thresh,dice,exp_rmspe,fbeta|})"
        ]
    },
    "Text Imports": {
        "prefix": "fastai:text:imports",
        "description": "Adds most important imports for the fastai NLP tasks",
        "body": [
            "from fastai import *",
            "from fastai.text import *"
        ]
    },
    "Text Dataset": {
        "prefix": "fastai:text:dataset",
        "description": "Creates a Dataset for NLP",
        "body": [
            "path = Path('${TM_DIRECTORY}') / '${1:data}'",
            "datasets = TextDataset${2|(df=None\\, create_mtd=TextMtd.DF\\, tokenizer=None,.from_ids(id_suff'_ids'\\, lbl_suff='_lbl'\\, itos='itos.pkl',.from_tokens(tok_suff='_tok'\\, lbl_suff='_lbl',.from_df(df\\, tokenizer=None,.from_one_folder(classes\\, tokenizer=None\\, suffle=True,.from_folder(classes=None\\, tokenizer=None\\, suffle=True|}, path=path, name='train', vocab=None, max_vocab=60000, chunksize=10000,  min_freq=2, n_labels=1, txt_cols=None, label_cols=None, classes=None, clear_cache=False)"
        ]
    },
    "Text DataBunch": {
        "prefix": "fastai:text:databunch",
        "description": "Creates a DataBuch for NLP",
        "body": [
            "path = Path('${TM_DIRECTORY}') / '${1:data'}",
            "data = ${2|TextDataBunch,TextLMDataBunch,TextClasDataBunch|}.${3|create(datasets,from_ids(trn_ids\\, trn_lbls\\, val_ids\\, val_lbls\\, vocab_size\\, tst_ids=None\\, classes=None,from_id_files(train='train'\\, valid='valid'\\, test=None\\, itos='itos.pkl',from_tokens(train='train'\\, valid='valid'\\, test=None\\, vocab=None,from_df(train_df\\, valid_df\\, test_df=None\\, tokenizer=None\\, vocab=None,from_csv(train='train'\\, valid='valid'\\, tokenizer=None\\, test=None\\, vocab=None,from_folder(train'train'\\, valid='valid'\\, tokenizer=None\\, test=None\\, shuffle=True\\, vocab=None|}, path=path)"
        ]
    },
    "Text DataBlock": {
        "prefix": "fastai:text:datablock",
        "description": "Creates a DataBlock for NLP",
        "body": [
            "path = Path('${TM_DIRECTORY}') / '${1:data'}",
            "data = (TextFileList.from_folder(path)\t# grap all the text files in path",
            "\t.${2|label_const(const=0)\t# label every item with const,label_from_csv(csv_fnames\\, fn_col=0\\, label_col=1\\, header='infer')\t# look in self.path/csv_fname for a csv loaded with an optional header containing the filenames in fn_col to get the corresponding label in label_col,label_from_folder(classes=None)\t# give a label to each filename depending on its folder,label_from_df(df\\, fn_col=0\\, label_col=1)\t# look in df for the filenames in fn_col to get the corresponding label in label_col,label_from_func(get_y_fn)\t# apply func to every input to get its label,label_from_re(pat\\, full_path=False)\t# apply the re in pat to determine the label of every filename|}",
            "\t.${3|split_by_folder(train='train'\\, valid='valid')\t# split the data depending on the folder (train or valid) in which the filenames are,random_split_by_pct(valid_pct=0.2)\t# split the items randomly by putting valid_pct in the validation set,split_by_files(valid_names)\t# split the data by using the names in valid_names for validation,split_by_fname_file(fname)\t# split the data by using the file names in fname for the validation set,split_by_idx(valid_idx)\t# split the data according to the indexes in valid_idx,split_by_valid_func(func)\t# split the data by result of func (which returns True for validation set)|})",
            "\t${4| ,.add_test_folder(test_folder='test'\\, label=None)\t# add test set containing items from test and an arbitrary label|}",
            "\t.datasets()\t# use TextDataset",
            "\t.tokenize(tokenizer=${5:None})\t# if None tokenize with defaults from fastai",
            "\t.numericalize(vocab=${6:None})\t# if None numericalize with defaults from fastai",
            "\t.databunch(${7|TextDataBunch\t# use a TextDataBunch,TextLMDataBunch\t# use a TextLMDataBunch,TextClasDataBunch\t# use a TextClasDataBunch|}))",
            "",
            "data.save('tmp_data')"
        ]
    },
    "Text DataBlock Language Model": {
        "prefix": "fastai:text:datablock-lm",
        "description": "Creates a DataBlock for NLP",
        "body": [
            "path = Path('${TM_DIRECTORY}') / '${1:data'}",
            "data_lm = (TextFileList.from_folder(path)\t# grap all the text files in path",
            "\t.${2|label_const(const=0)\t# label every item with const,label_from_csv(csv_fnames\\, fn_col=0\\, label_col=1\\, header='infer')\t# look in self.path/csv_fname for a csv loaded with an optional header containing the filenames in fn_col to get the corresponding label in label_col,label_from_folder(classes=None)\t# give a label to each filename depending on its folder,label_from_df(df\\, fn_col=0\\, label_col=1)\t# look in df for the filenames in fn_col to get the corresponding label in label_col,label_from_func(get_y_fn)\t# apply func to every input to get its label,label_from_re(pat\\, full_path=False)\t# apply the re in pat to determine the label of every filename|}",
            "\t.${3|split_by_folder(train='train'\\, valid='valid')\t# split the data depending on the folder in which the filenames are,random_split_by_pct(valid_pct=0.2)\t# split the items randomly by putting valid_pct in the validation set,split_by_files(valid_names)\t# split the data by using the names in valid_names for validation,split_by_fname_file(fname)\t# split the data by using the file names in fname for the validation set,split_by_idx(valid_idx)\t# split the data according to the indexes in valid_idx,split_by_valid_func(func)\t# split the data by result of func (which returns True for validation set)|})",
            "\t${4| ,.add_test_folder(test_folder='test'\\, label=None)\t# add test set containing items from test and an arbitrary label|}",
            "\t.datasets()\t# use TextDataset",
            "\t.tokenize(tokenizer=${5:None})\t# if None tokenize with defaults from fastai",
            "\t.numericalize(vocab=${6:None})\t# if None numericalize with defaults from fastai",
            "\t.databunch(TextLMDataBunch))\t# use a TextLMDataBunch",
            "",
            "data_lm.save('tmp_lm')"
        ]
    },
    "Text DataBlock Classifier": {
        "prefix": "fastai:text:datablock-clas",
        "description": "Creates a DataBlock for NLP",
        "body": [
            "path = Path('${TM_DIRECTORY}') / '${1:data'}",
            "data_clas = (TextFileList.from_folder(path)\t# grap all the text files in path",
            "\t.${2|label_const(const=0)\t# label every item with const,label_from_csv(csv_fnames\\, fn_col=0\\, label_col=1\\, header='infer')\t# look in self.path/csv_fname for a csv loaded with an optional header containing the filenames in fn_col to get the corresponding label in label_col,label_from_folder(classes=None)\t# give a label to each filename depending on its folder,label_from_df(df\\, fn_col=0\\, label_col=1)\t# look in df for the filenames in fn_col to get the corresponding label in label_col,label_from_func(get_y_fn)\t# apply func to every input to get its label,label_from_re(pat\\, full_path=False)\t# apply the re in pat to determine the label of every filename|}",
            "\t.${3|split_by_folder(train='train'\\, valid='valid')\t# split the data depending on the folder in which the filenames are,random_split_by_pct(valid_pct=0.2)\t# split the items randomly by putting valid_pct in the validation set,split_by_files(valid_names)\t# split the data by using the names in valid_names for validation,split_by_fname_file(fname)\t# split the data by using the file names in fname for the validation set,split_by_idx(valid_idx)\t# split the data according to the indexes in valid_idx,split_by_valid_func(func)\t# split the data by result of func (which returns True for validation set)|})",
            "\t${4| ,.add_test_folder(test_folder='test'\\, label=None)\t# add test set containing items from test and an arbitrary label|}",
            "\t.datasets()\t# use TextDataset",
            "\t.tokenize(tokenizer=${5:None})\t# if None tokenize with defaults from fastai",
            "\t.numericalize(vocab=${6:data_lm.vocab})\t# if None numericalize with defaults from fastai",
            "\t.databunch(TextClasDataBunch, bs=${7:50}))\t# use a TextClasDataBunch",
            "",
            "data_clas.save('tmp_clas')"
        ]
    },
    "Text Learner": {
        "prefix": "fastai:text:learner",
        "description": "Creates a learner for NLP",
        "body": [
            "learn = RNNLearner${2|(model\\, split_func=None\\, clip=None\\, adjust=False\\, alpha=2.\\, beta=1.,.language_model(emb_sz=400\\, nh=1150\\, nl=3\\, pad_token=1\\, drop_mult=1.\\, tie_weights=True\\, bias=True\\, qrnn=False\\, pretrained_model=None\\, pretrained_fnames=None,.classifier(max_len=70*20\\, emb_sz=400\\, nh=1150\\, nl=3\\, lin_ftrs=None\\, ps=None\\, pad_token=1\\, drop_mult=1.\\, qrnn=False|}, data=data, bptt=70)"
        ]
    },
    "Language Model": {
        "prefix": "fastai:text:lm-learner",
        "description": "Creates a language learner",
        "body": [
            "learn = language_model_learner(${1:data}, bptt=${2:70}, emb_sz=${3:400}, nh=${4:1150}, nl=${5:3})"
        ]
    },
    "Text Classifier": {
        "prefix": "fastai:text:clas-learner",
        "description": "Creates a text classifier",
        "body": [
            "learn = text_classifier_learner(${1:data}, bptt=${2:70}, emb_sz=${3:400}, nh=${4:1150}, nl=${5:3})"
        ]
    },
    "Collaborative Filtering Dataset": {
        "prefix": "fastai:colab:dataset",
        "description": "Creates a dataset for collaborative filtering",
        "body": [
            "datasets = CollabFilteringDataset${1|(user\\, item\\, ratings),.from_df(rating_df\\, pct_valt=0.2\\, user_name=None\\, item_name=None\\, rating_name=None),.from_csv(csv_name)|}"
        ]
    },
    "Collaborative Filtering Learner": {
        "prefix": "fastai:colab:learner",
        "description": "Creates a learner for collaborative filtering",
        "body": [
            "learn = get_collab_learner(${1:ratings}, n_factors=${2:n_factors}, user_name=${3:None}, item_name=${4:None}, rating_name=${5:None}, pct_val=0.2, test=None, metrics=None, min_score=None, max_score=None)"
        ]
    },
    "Cifar Example": {
        "prefix": "fastai:examples:cifar",
        "description": "Cifar code example",
        "body": [
            "from fastai import *",
            "from fastai.vision import *",
            "from fastai.vision.models.wrn import wrn_22",
            "",
            "torch.backends.cudnn.benchmark = True",
            "",
            "path = untar_data(URLs.CIFAR)",
            "ds_tfms = ([*rand_pad(4, 32), flip_lr(p=0.5)], [])",
            "data = ImageDataBunch.from_folder(path, valid='test', ds_tfms=ds_tfms, bs=512).normalize(cifar_stats)",
            "",
            "learn = Learner(data, wrn_22(), metrics=accuracy).to_fp16()",
            "learn.fit_one_cycle(30, 3e-3, wd=0.4, div_factor=10, pct_start=0.5)",
            "",
            "# with mixup",
            "learn = Learner(data, wrn_22(), metrics=accuracy).to_fp16().mixup()",
            "learn.fit_one_cycle(24, 3e-3, wd=0.2, div_factor=10, pct_start=0.5)"
        ]
    },
    "Colab Example": {
        "prefix": "fastai:examples:colab",
        "description": "Colaborative filtering code example",
        "body": [
            "from fastai import *          # Quick access to most common functionality",
            "from fastai.collab import *   # Quick access to collab filtering functionality",
            "",
            "path = untar_data(URLs.ML_SAMPLE)",
            "ratings = pd.read_csv(path/'ratings.csv')",
            "series2cat(ratings, 'userId', 'movieId')",
            "",
            "learn = get_collab_learner(ratings, n_factors=50, min_score=0., max_score=5.)",
            "learn.fit_one_cycle(4, 5e-3)"
        ]
    },
    "Dogs-Cats Example": {
        "prefix": "fastai:examples:dogs-cats",
        "description": "Dogs-cats code example",
        "body": [
            "from fastai import *",
            "from fastai.vision import *",
            "",
            "path = untar_data(URLs.DOGS)",
            "data = ImageDataBunch.from_folder(path, ds_tfms=get_transforms(), size=224).normalize(imagenet_stats)",
            "",
            "learn = create_cnn(data, models.resnet34, metrics=accuracy)",
            "learn.fit_one_cycle(1)",
            "",
            "learn.unfreeze()",
            "learn.fit_one_cycle(6, slice(1e-5,3e-4), pct_start=0.05)",
            "",
            "accuracy(*learn.TTA())"
        ]
    },
    "Adult Example": {
        "prefix": "fastai:examples:adult",
        "description": "Adult code example",
        "body": [
            "from fastai import *          # Quick access to most common functionality",
            "from fastai.tabular import *  # Quick access to tabular functionality",
            "",
            "path = untar_data(URLs.ADULT_SAMPLE)",
            "df = pd.read_csv(path/'adult.csv')",
            "train_df, valid_df = df[:-2000].copy(),df[-2000:].copy()",
            "",
            "dep_var = '>=50k'",
            "cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']",
            "data = TabularDataBunch.from_df(path, train_df, valid_df, dep_var,",
            "\t\t\t\t\t\t\t\ttfms=[FillMissing, Categorify], cat_names=cat_names)",
            "",
            "learn = get_tabular_learner(data, layers=[200,100], metrics=accuracy)",
            "learn.fit(1, 1e-2)"
        ]
    },
    "Imdb Example": {
        "prefix": "fastai:examples:imdb",
        "description": "Imdb code example",
        "body": [
            "from fastai import *        # Quick access to most common functionality",
            "from fastai.text import *   # Quick access to NLP functionality",
            "",
            "path = untar_data(URLs.IMDB_SAMPLE)",
            "df = pd.read_csv(path/'texts.csv', header=None)",
            "",
            "data_lm = TextLMDataBunch.from_csv(path, 'texts.csv')",
            "data_clas = TextClasDataBunch.from_csv(path, 'texts.csv', vocab=data_lm.train_ds.vocab, bs=42)",
            "",
            "learn = language_model_learner(data_lm, pretrained_model=URLs.WT103)",
            "learn.unfreeze()",
            "learn.fit(2, slice(1e-4,1e-2))",
            "",
            "learn.save_encoder('enc')",
            "",
            "learn = text_classifier_learner(data_clas)",
            "learn.load_encoder('enc')",
            "learn.fit(3, 1e-3)"
        ]
    },
    "Mnist Example": {
        "prefix": "fastai:examples:mnist",
        "description": "Mnist code example",
        "body": [
            "",
            "import fastai",
            "from fastai import *          # Quick access to most common functionality",
            "from fastai.vision import *   # Quick access to computer vision functionality",
            "",
            "path = untar_data(URLs.MNIST_SAMPLE)",
            "data = ImageDataBunch.from_folder(path, ds_tfms=(rand_pad(2, 28), []), bs=64)",
            "data.normalize(imagenet_stats)",
            "",
            "learn = create_cnn(data, models.resnet18, metrics=accuracy)",
            "learn.fit_one_cycle(1, 0.01)",
            "",
            "accuracy(*learn.get_preds())"
        ]
    }
}